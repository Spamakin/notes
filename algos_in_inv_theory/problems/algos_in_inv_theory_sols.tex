\documentclass[letterpaper, 11pt, oneside]{book}

\usepackage{style}  % If you feel like procrastinating, mess with this file
\usepackage{algo}   % Thank you Jeff, very cool!

\addbibresource{refs.bib}

% Required reading
% https://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf
%   Along with required viewing:
%   https://www.youtube.com/watch?v=N6QEgbPWUrg&list=PLOdeqCXq1tXihn5KmyB2YTOqgxaUkcNYG
% https://faculty.math.illinois.edu/~west/grammar.html

% % % % % % % % % %
%     Cursor      %
%     Parking     %
%     Lot         %
% % % % % % % % % %

% Disable check for mismatched parens/brackets/braces
%   chktex-file 9
% Disable check for different counts of parents/brackets/braces
%   chktex-file 17
% Exclude these environments from syntax checking
%   VerbEnvir { tikzcd }

\regtotcounter{figure}

\title{\vspace{-100pt} {\Huge Algorithms in Invariant Theory} \\ {\small With $\total{figure}$ Figures}}
\author{\Large Anakin Dey}
\DTMsavenow{now}
\date{\small Last Edited on \today\ at \DTMfetchhour{now}:\DTMfetchminute{now}}

% Cover page number chicanery
\newcommand{\CoverName}{Cover}

\begin{document}
\frontmatter
\renewcommand{\thepage}{\CoverName}
\maketitle

\pagenumbering{roman}

\tableofcontents
\clearpage


% \listoftheorems[ignoreall, show={defn}, title={List of Definitions}]
%
% \listoftheorems[ignoreall, show={ex}, title={List of Examples and Counterexamples}]

\chapter*{Preface}

A core interest of mine (at the time of writing this) is algorithms in the context of commutative algebra and algebraic geometry.
As such, Bernd Sturmfel's text \emph{Algorithms in Invariant Theory}~\cite{book:AlgosInInvTheory} is a good resource for first learning this stuff.
Perhaps in the future I'll include notes and some source code

\mainmatter

\chapter{Introduction}

\section{Symmetric Polynomials}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.1.5]
  From~[Page 23, 2.11']\cite{book:MacdonaldSymmetricHall}, we have the following identities
  \begin{align*}
    1 \cdot \sigma_{1} &= p_{1}, \\
    2 \cdot \sigma_{2} &= p_{1} \sigma_{1} - p_{2}, \\
    3 \cdot \sigma_{3} &= p_{1} \sigma_{2} - p_{2} \sigma_{1} + p_{3}, \\
                       &\vdots \\
    k \cdot \sigma_{k} &= \sum_{r = 1}^{k} (-1)^{r - 1} p_{r} \sigma_{k - r}.
  \end{align*}
Treating the $\sigma_{i}$ as indeterminants, we can re-express the above system of equations:
\begin{align*}
  p_{1} &= 1 \cdot \sigma_{1}, \\
  p_{2} &= p_{1} \sigma_{1} - 2 \cdot \sigma_{2}, \\
  p_{3} &= p_{2} \sigma_{1} - p_{1} \sigma_{2} + 3 \cdot \sigma_{3}, \\
        &\vdots \\
  p_{k} &= \pqty{\sum_{r = 1}^{k - 1} (-1)^{r - 1} p_{k - r} \sigma_{r}} + (-1)^{k - 1} \cdot k \sigma_{k}.
\end{align*}
Consider $\sigma_{1}, -\sigma_{2}, \sigma_{3}, \ldots, (-1)^{n} \sigma_{n - 1}, \sigma_{n}$ as indeterminants.
Thus, we obtain the following matrix equation:
\[
  \begin{pmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    p_{1} & 2 & 0 & \cdots & 0 \\
    p_{2} & p_{1} & 3 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & \cdots & (-1)^{k} \cdot k
  \end{pmatrix}
  \begin{pmatrix}
    \sigma_{1} \\
    -\sigma_{2} \\
    \vdots \\
    (-1)^{k} \sigma_{k - 1} \\
    \sigma_{k}
  \end{pmatrix}
  =
  \begin{pmatrix}
    p_{1} \\
    p_{2} \\
    \vdots \\
    p_{k - 1} \\
    p_{k}
  \end{pmatrix}.
\]
Then, Cramer's rule yields that
\begin{align*}
  \sigma_{k} &=
  \det
  \begin{pmatrix}
    1 & 0 & 0 & \cdots & p_{1} \\
    p_{1} & 2 & 0 & \cdots & p_{2} \\
    p_{2} & p_{1} & 3 & \cdots & p_{3} \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & \cdots & p_{k}
  \end{pmatrix}
  \det
  \begin{pmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    p_{1} & 2 & 0 & \cdots & 0 \\
    p_{2} & p_{1} & 3 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & \cdots & (-1)^{k} \cdot k
  \end{pmatrix}^{-1} \\
    &= \frac{(-1)^{k}}{k!}
  \det
  \begin{pmatrix}
    1 & 0 & 0 & \cdots & p_{1} \\
    p_{1} & 2 & 0 & \cdots & p_{2} \\
    p_{2} & p_{1} & 3 & \cdots & p_{3} \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & \cdots & p_{k}
  \end{pmatrix} \\
    &= \frac{(-1)^{k}}{k!} \cdot (-1)^{k}
  \det
  \begin{pmatrix}
    p_{1} & 1 & 0 & \cdots & 0 \\
    p_{2} & p_{1} & 2 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & p_{1} & k - 1 \\
    p_{k} & p_{k - 1} & \cdots & \cdots & p_{1}
  \end{pmatrix}
     = \frac{1}{k!}
  \det
  \begin{pmatrix}
    p_{1} & 1 & 0 & \cdots & 0 \\
    p_{2} & p_{1} & 2 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \ddots & \vdots \\
    p_{k - 1} & p_{k - 2} & \cdots & p_{1} & k - 1 \\
    p_{k} & p_{k - 1} & \cdots & \cdots & p_{1}
  \end{pmatrix}.
\end{align*}
\end{sol}

\clearpage

\section{\Grobner\ Bases}

\begin{lem}
  Let $R = \C[x_{1}, \ldots, x_{n}]$.
  Then with the usual grading, let $H(R, z) \defeq \sum_{d = 0}^{\infty} \dim_{\C}(R_{d}) z^{d}$.
  We have that
  \[
    H(R, z) \defeq \sum_{d = 0}^{\infty} \dim_{\C}(R_{d}) z^{d} = \sum_{d = 0}^{\infty} \binom{d + n - 1}{n - 1} = \frac{1}{(1 - z)^{n}}.
  \]
\end{lem}
\begin{pf}
  To see that $H(R, z) = \sum_{d = 0}^{\infty} \binom{d + n - 1}{n - 1}$, just count the number of monomials of degree $d$ in $n$ variables.
  The value $\binom{d + n - 1}{n - 1}$ is the number of non-negative integer solutions to $a_{1} + \cdots + a_{n} = d$.
  Each solution corresponds to a monomial $x_{1}^{a_{1}} \cdots x_{n}^{a_{n}}$.
  Then to see that $H(R, z) = \frac{1}{(1 - z)^{n}}$, consider the product of infinite sums $(1 + z + z^{2} + \cdots) \cdots (1 + z + z^{2} + \cdots)$ a total of $n$-times.
  Then the coefficient of $z^{d}$ again corresponds to the number of such non-negative integer solutions.
  Since $\frac{1}{1 - z} = 1 + z + z^{2} + \cdots$, we obtain the desired equality.
\end{pf}

\begin{lem}
  For $1 \leq k \leq n$, we have that
  \[
    h_{k}(x_{k}, \ldots, x_{n}) + \sum_{i = 1}^{k} (-1)^{i}h_{k - i}(x_{k}, \ldots, x_{n})\sigma_{i}(x_{1}, \ldots, x_{n}) = 0.
  \]
\end{lem}
\begin{pf}
  Using the generating functions for the $h_{i}$ and $\sigma_{i}$, we have that the above expression is the coefficient of $t^{k}$ in the product
  \[
    \prod_{i = k}^{n} (1 - x_{i}t)^{-1} \cdot \prod_{i = 1}^{n}(1 - x_{i} t) = \prod_{i = 1}^{k - 1} (1 - x_{i}t).
  \]
  However, the right-hand side of this has degree $k - 1$ in $t$.
  Thus, the coefficient of $t^{k}$ is indeed $0$.
\end{pf}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.2.1]
  Let $M$ be a set of monomial generators for $\init(I)$ and let $m$ be minimally nonstandard.
  Since $m$ is a monomial and in $\init(I)$, we have that $m' \mid m$ for some monomial $m' \in M$.
  However, note that $m' \in \init(I)$ and furthermore by the fact that $m$ is minimally nonstandard, we cannot have that $m'$ strictly divides $m$.
  Thus, $m' = m$ and $m \in M$.
  Then by Dickson's Lemma, we have that $M$ is a finite set and thus there are finitely many minimally nonstandard monomials.
\end{sol}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.2.2]
  This is~\cite[Chapter 2, \S 7, Theorem 5]{book:IVA}.
\end{sol}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.2.3]
  This is~\cite[Chapter 3, \S 1, Theorem 2]{book:IVA}.
\end{sol}

\clearpage

\begin{sol}[\cite{book:AlgosInInvTheory} 1.2.4]
  This is following~\cite{Robbiano_term_orders} and~\cite{book:Singular_Introduction}.
  Let $\geq$ be a monomial ordering on $\C[x_{1}, \ldots, x_{n}]$.
  This is equivalent to a total semigroup ordering $\geq$ on $\Z^{n}$.
  Such a semigroup ordering gives a unique total ordering on $\Q^{n}$.
  To see this, for $\overline{q} = (q_{1}, \ldots, q_{n}) \in \Q^{n}$, let $m \in \Z$ such that $m \cdot q_{i} \in \Z$ for all $i$.
  Then say that $\overline{q} \geq 0$ if and only if $m \cdot \overline{q} \geq 0$ where the latter ordering is in $\Z^{n}$.

  Let $V \subseteq \Q^{n}$ be a $\Q$-vector space with $\dim_{\Q}(V) = r$.
  Then let
  \[
    V_{0} \defeq \Set{z \in \R^{n} | \forall \e > 0, \exists\; z_{+}(\e), z_{-}(\e) \in V \cap B_{\e}(z) \text{ such that } z_{+}(\e) > 0, z_{-}(\e) < 0}.
  \]
  Then $V_{0}$ is clearly a $\R$-subspace of $\R^{n}$.
  With the ordering $\geq$ on $\Q^{n}$, we can define $V_{+}$ and $V_{-}$ depending on if $\overline{q} \geq 0$ or $\overline{q} < 0$.
  We define a map $\pi\colon V \to \set{-1, 1}$, where $V$ has the Euclidean topology and $\set{-1, 1}$ has the discrete topology.
  Let $\pi(q) = 1$ if there exists an open ball $U_{\e}(q)$ such that $U_{\e}(q) \cap V \subseteq V_{+}$ and $\pi(q) = -1$ if there exists an open ball $U_{\e}(q)$ such that $U_{\e}(q) \cap V \subseteq V_{-}$.
  Then $\pi$ is continuous.
  Recall that topological vector spaces over $\R$ are connected.
  Thus, we cannot have that $\dim_{\R} V_{0} < r - 1$ as if it were, then $V_{\R} \setminus V_{0}$ would be connected \quest{why is this bad?}.
  Then suppose that $\dim_{\R} V_{0} = r$.
  Then we have an ordered basis $e_{1}, \ldots, e_{r}$ such that $e_{i} > 0$ for all $i$.
  But then the linear combinations of the $e_{i}$ with positive coefficients are a subspace of $V_{+}$ which is a contradiction \quest{why?}.

  To construct the first row of the matrix, start with $V = \Q^{n}$ and consider the obtained $V_{0}$.
  Then the dimension $1$ subspace orthogonal to $V_{0}$ in $\R^{n}$ defines the first row of $A$.
  We can continue this construction inductively to obtain the full matrix $A$.
\end{sol}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.2.6]
  First, we recall some definitions.
  The $S$-polynomial of $f$ and $g$ is
  \[
    S(f, g) \defeq \frac{\lcm(\lm(f), \lm(g))}{\lt(f)} f - \frac{\lcm(\lm(f), \lm(g))}{\lt(g)} g.
  \]
  For a set of polynomials $\mathcal{F} = \set{f_{1}, \ldots, f_{t}} \subseteq k[x_{1}, \ldots, x_{n}]$, we write $f \to_{\mathcal{F}} 0$ if there exists $a_{1}, \ldots, a_{t} \in k[x_{1}, \ldots, x_{n}]$ such that $a_{1} f_{1} + \cdots + a_{t} f_{t} = 0$.
  Then~\cite[Chapter 2, \S 9, Theorem 3]{book:IVA} says that a basis $\mathcal{F} = \set{f_{1}, \ldots f_{t}}$ is a \Grobner\ basis for $G$ if and only if $S(f_{i}, f_{j}) \to_{\mathcal{F}} 0$ for all $i \neq j$.
  But~\cite[Chapter 2, \S 9, Proposition 4]{book:IVA} says that for $f, g \in \mathcal{F}$ with relatively prime initial monomials, we have that $S(f, g) \to_{\mathcal{F}} 0$.
  This proves the claim.
\end{sol}

\clearpage

\section{What is Invariant Theory?}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.3.1]
  Let $\Gamma$ be a finite group.
  Consider $f(x) = \prod_{g \in \Gamma} g \cdot x$.
  Then $f$ is well defined as $\Gamma$ is finite, invariant under the action of $\Gamma$, and of degree $\abs{\Gamma} > 0$.

  Now suppose $\Gamma$ is the subgroup of matrices $\lambda I_{n}$ for $\lambda \in \C^{\times}$.
  Then for any polynomial $f(\overline{x}) = \sum_{I} \overline{a}^{I} \overline{x}^{I} \in \C[\overline{x}]^{\Gamma}$ and for any such $\lambda I_{n} \in \Gamma$, we have that
  \[
    \sum_{I} \overline{a}^{I} \overline{x}^{I} = f(\overline{x}) = \lambda I_{n} \cdot f(\overline{x}) = \sum_{I} \overline{a}^{I} \lambda^{\abs{I}} \overline{x}^{I}.
  \]
  Then comparing coefficients, we deduce that $f(\overline{x})$ is fixed if and only if $f(\overline{x}) \in \C$.
  Thus, $\C[\overline{x}]^{\Gamma} = \C$.
\end{sol}

\begin{sol}[\cite{book:AlgosInInvTheory} 1.3.3]
  Fix $a_{1}, \ldots, a_{n} \in \Z$ and let $\Gamma = \set{\diag(t^{a_{1}, \ldots, t^{a_{n}}}) | t \in \C^{\times}}$.
  For $d \in \Gamma$ and a monomial $x_{1}^{\nu_{1}} \cdots x_{n}^{\nu_{n}}$, we have that $d \cdot x_{1}^{\nu_{1}} \cdots x_{n}^{\nu_{n}} = t^{a_{1}\nu_{1} + \cdots + a_{n}\nu_{n}} x_{1}^{\nu_{1}} \cdots x_{n}^{\nu_{1}}$.
  Thus, we want to determine the set of fixed exponent vectors
  \[
    \mathcal{M} = \set{(\nu_{1}, \ldots, \nu_{n}) \in \Z^{n} | \nu_{1}, \ldots, \nu_{n} \geq 0, a_{1}\nu_{1} + \cdots + a_{n}\nu_{n} = 0}.
  \]
  This is exactly the object of student in \S 1.4, and in particular is solved by~\cite[Algorithm 1.4.5]{book:AlgosInInvTheory}.
  \quest{Is there a more direct way to see this?}
\end{sol}

\printbibliography
\end{document}
